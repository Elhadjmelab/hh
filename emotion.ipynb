{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'to_categorical' from 'keras.utils' (C:\\Users\\Lenovo\\anaconda3\\envs\\ONE\\lib\\site-packages\\keras\\utils\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ImageDataGenerator\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_categorical\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'to_categorical' from 'keras.utils' (C:\\Users\\Lenovo\\anaconda3\\envs\\ONE\\lib\\site-packages\\keras\\utils\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FAST_RUN = False\n",
    "s=128\n",
    "IMAGE_SIZE=(s,s)\n",
    "IMAGE_CHANNELS=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "#correct df path\n",
    "\n",
    "root_dir = \"C:\\\\Users\\\\Lenovo\\\\Desktop\\\\emotion\\\\eINTERFACE_2021_Image\\\\train\"\n",
    "categories = []\n",
    "\n",
    "for category_label, (root, dirs, files) in enumerate(os.walk(root_dir)):\n",
    "    if category_label == 0:\n",
    "        continue  # Skip the root directory itself\n",
    "    category_name = os.path.basename(root)\n",
    "    for filename in files:\n",
    "        file_path = os.path.join(root, filename)  # Obtain full file path\n",
    "        categories.append((file_path, category_name))  # Append full file path and category name\n",
    "\n",
    "train_df = pd.DataFrame(categories, columns=['image', 'emotion'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\Users\\Lenovo\\Desktop\\emotion\\eINTERFACE_202...</td>\n",
       "      <td>Anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:\\Users\\Lenovo\\Desktop\\emotion\\eINTERFACE_202...</td>\n",
       "      <td>Anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:\\Users\\Lenovo\\Desktop\\emotion\\eINTERFACE_202...</td>\n",
       "      <td>Anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:\\Users\\Lenovo\\Desktop\\emotion\\eINTERFACE_202...</td>\n",
       "      <td>Anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:\\Users\\Lenovo\\Desktop\\emotion\\eINTERFACE_202...</td>\n",
       "      <td>Anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11470</th>\n",
       "      <td>C:\\Users\\Lenovo\\Desktop\\emotion\\eINTERFACE_202...</td>\n",
       "      <td>Surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11471</th>\n",
       "      <td>C:\\Users\\Lenovo\\Desktop\\emotion\\eINTERFACE_202...</td>\n",
       "      <td>Surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11472</th>\n",
       "      <td>C:\\Users\\Lenovo\\Desktop\\emotion\\eINTERFACE_202...</td>\n",
       "      <td>Surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11473</th>\n",
       "      <td>C:\\Users\\Lenovo\\Desktop\\emotion\\eINTERFACE_202...</td>\n",
       "      <td>Surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11474</th>\n",
       "      <td>C:\\Users\\Lenovo\\Desktop\\emotion\\eINTERFACE_202...</td>\n",
       "      <td>Surprise</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11475 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   image   emotion\n",
       "0      C:\\Users\\Lenovo\\Desktop\\emotion\\eINTERFACE_202...     Anger\n",
       "1      C:\\Users\\Lenovo\\Desktop\\emotion\\eINTERFACE_202...     Anger\n",
       "2      C:\\Users\\Lenovo\\Desktop\\emotion\\eINTERFACE_202...     Anger\n",
       "3      C:\\Users\\Lenovo\\Desktop\\emotion\\eINTERFACE_202...     Anger\n",
       "4      C:\\Users\\Lenovo\\Desktop\\emotion\\eINTERFACE_202...     Anger\n",
       "...                                                  ...       ...\n",
       "11470  C:\\Users\\Lenovo\\Desktop\\emotion\\eINTERFACE_202...  Surprise\n",
       "11471  C:\\Users\\Lenovo\\Desktop\\emotion\\eINTERFACE_202...  Surprise\n",
       "11472  C:\\Users\\Lenovo\\Desktop\\emotion\\eINTERFACE_202...  Surprise\n",
       "11473  C:\\Users\\Lenovo\\Desktop\\emotion\\eINTERFACE_202...  Surprise\n",
       "11474  C:\\Users\\Lenovo\\Desktop\\emotion\\eINTERFACE_202...  Surprise\n",
       "\n",
       "[11475 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emotion\n",
       "Fear         1922\n",
       "Happiness    1922\n",
       "Sadness      1922\n",
       "Surprise     1922\n",
       "Anger        1896\n",
       "Disgust      1891\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['emotion'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "#correct df path\n",
    "\n",
    "root_dir = \"C:\\\\Users\\\\Lenovo\\\\Desktop\\\\emotion\\\\eINTERFACE_2021_Image\\\\test\"\n",
    "categories = []\n",
    "\n",
    "for category_label, (root, dirs, files) in enumerate(os.walk(root_dir)):\n",
    "    if category_label == 0:\n",
    "        continue  # Skip the root directory itself\n",
    "    category_name = os.path.basename(root)\n",
    "    for filename in files:\n",
    "        file_path = os.path.join(root, filename)  # Obtain full file path\n",
    "        categories.append((file_path, category_name))  # Append full file path and category name\n",
    "\n",
    "test_df = pd.DataFrame(categories, columns=['image', 'emotion'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\Users\\Lenovo\\Desktop\\emotion\\eINTERFACE_202...</td>\n",
       "      <td>Anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:\\Users\\Lenovo\\Desktop\\emotion\\eINTERFACE_202...</td>\n",
       "      <td>Anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:\\Users\\Lenovo\\Desktop\\emotion\\eINTERFACE_202...</td>\n",
       "      <td>Anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:\\Users\\Lenovo\\Desktop\\emotion\\eINTERFACE_202...</td>\n",
       "      <td>Anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:\\Users\\Lenovo\\Desktop\\emotion\\eINTERFACE_202...</td>\n",
       "      <td>Anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1433</th>\n",
       "      <td>C:\\Users\\Lenovo\\Desktop\\emotion\\eINTERFACE_202...</td>\n",
       "      <td>Surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1434</th>\n",
       "      <td>C:\\Users\\Lenovo\\Desktop\\emotion\\eINTERFACE_202...</td>\n",
       "      <td>Surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>C:\\Users\\Lenovo\\Desktop\\emotion\\eINTERFACE_202...</td>\n",
       "      <td>Surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>C:\\Users\\Lenovo\\Desktop\\emotion\\eINTERFACE_202...</td>\n",
       "      <td>Surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>C:\\Users\\Lenovo\\Desktop\\emotion\\eINTERFACE_202...</td>\n",
       "      <td>Surprise</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1438 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  image   emotion\n",
       "0     C:\\Users\\Lenovo\\Desktop\\emotion\\eINTERFACE_202...     Anger\n",
       "1     C:\\Users\\Lenovo\\Desktop\\emotion\\eINTERFACE_202...     Anger\n",
       "2     C:\\Users\\Lenovo\\Desktop\\emotion\\eINTERFACE_202...     Anger\n",
       "3     C:\\Users\\Lenovo\\Desktop\\emotion\\eINTERFACE_202...     Anger\n",
       "4     C:\\Users\\Lenovo\\Desktop\\emotion\\eINTERFACE_202...     Anger\n",
       "...                                                 ...       ...\n",
       "1433  C:\\Users\\Lenovo\\Desktop\\emotion\\eINTERFACE_202...  Surprise\n",
       "1434  C:\\Users\\Lenovo\\Desktop\\emotion\\eINTERFACE_202...  Surprise\n",
       "1435  C:\\Users\\Lenovo\\Desktop\\emotion\\eINTERFACE_202...  Surprise\n",
       "1436  C:\\Users\\Lenovo\\Desktop\\emotion\\eINTERFACE_202...  Surprise\n",
       "1437  C:\\Users\\Lenovo\\Desktop\\emotion\\eINTERFACE_202...  Surprise\n",
       "\n",
       "[1438 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "#correct df path\n",
    "\n",
    "root_dir = \"C:\\\\Users\\\\Lenovo\\\\Desktop\\\\emotion\\\\eINTERFACE_2021_Image\\\\val\"\n",
    "categories = []\n",
    "\n",
    "for category_label, (root, dirs, files) in enumerate(os.walk(root_dir)):\n",
    "    if category_label == 0:\n",
    "        continue  # Skip the root directory itself\n",
    "    category_name = os.path.basename(root)\n",
    "    for filename in files:\n",
    "        file_path = os.path.join(root, filename)  # Obtain full file path\n",
    "        categories.append((file_path, category_name))  # Append full file path and category name\n",
    "\n",
    "validate_df = pd.DataFrame(categories, columns=['image', 'emotion'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\Users\\Lenovo\\Desktop\\emotion\\eINTERFACE_202...</td>\n",
       "      <td>Anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:\\Users\\Lenovo\\Desktop\\emotion\\eINTERFACE_202...</td>\n",
       "      <td>Anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:\\Users\\Lenovo\\Desktop\\emotion\\eINTERFACE_202...</td>\n",
       "      <td>Anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:\\Users\\Lenovo\\Desktop\\emotion\\eINTERFACE_202...</td>\n",
       "      <td>Anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:\\Users\\Lenovo\\Desktop\\emotion\\eINTERFACE_202...</td>\n",
       "      <td>Anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1428</th>\n",
       "      <td>C:\\Users\\Lenovo\\Desktop\\emotion\\eINTERFACE_202...</td>\n",
       "      <td>Surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1429</th>\n",
       "      <td>C:\\Users\\Lenovo\\Desktop\\emotion\\eINTERFACE_202...</td>\n",
       "      <td>Surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1430</th>\n",
       "      <td>C:\\Users\\Lenovo\\Desktop\\emotion\\eINTERFACE_202...</td>\n",
       "      <td>Surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1431</th>\n",
       "      <td>C:\\Users\\Lenovo\\Desktop\\emotion\\eINTERFACE_202...</td>\n",
       "      <td>Surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1432</th>\n",
       "      <td>C:\\Users\\Lenovo\\Desktop\\emotion\\eINTERFACE_202...</td>\n",
       "      <td>Surprise</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1433 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  image   emotion\n",
       "0     C:\\Users\\Lenovo\\Desktop\\emotion\\eINTERFACE_202...     Anger\n",
       "1     C:\\Users\\Lenovo\\Desktop\\emotion\\eINTERFACE_202...     Anger\n",
       "2     C:\\Users\\Lenovo\\Desktop\\emotion\\eINTERFACE_202...     Anger\n",
       "3     C:\\Users\\Lenovo\\Desktop\\emotion\\eINTERFACE_202...     Anger\n",
       "4     C:\\Users\\Lenovo\\Desktop\\emotion\\eINTERFACE_202...     Anger\n",
       "...                                                 ...       ...\n",
       "1428  C:\\Users\\Lenovo\\Desktop\\emotion\\eINTERFACE_202...  Surprise\n",
       "1429  C:\\Users\\Lenovo\\Desktop\\emotion\\eINTERFACE_202...  Surprise\n",
       "1430  C:\\Users\\Lenovo\\Desktop\\emotion\\eINTERFACE_202...  Surprise\n",
       "1431  C:\\Users\\Lenovo\\Desktop\\emotion\\eINTERFACE_202...  Surprise\n",
       "1432  C:\\Users\\Lenovo\\Desktop\\emotion\\eINTERFACE_202...  Surprise\n",
       "\n",
       "[1433 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(416, 416, 3)    1438\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "size = []\n",
    "\n",
    "for filename in test_df['image']:\n",
    "    image = plt.imread(filename)\n",
    "    size.append(image.shape)\n",
    "\n",
    "size_series = pd.Series(size).value_counts()\n",
    "print(size_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 126, 126, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 63, 63, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 61, 61, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 28800)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               3686528   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 774       \n",
      "=================================================================\n",
      "Total params: 3,692,390\n",
      "Trainable params: 3,692,390\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\n",
    "# Initialising the CNN\n",
    "model = Sequential()\n",
    "\n",
    "# Step 1 - Convolution\n",
    "model.add(Conv2D(16, (3, 3), input_shape = (128, 128, 3), activation = 'relu'))\n",
    "\n",
    "# Step 2 - Pooling\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Adding a second convolutional layer\n",
    "model.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "\n",
    "\n",
    "# Step 3 - Flattening\n",
    "model.add(Flatten())\n",
    "\n",
    "# Step 4 - Full connection\n",
    "model.add(Dense(units = 128, activation = 'relu'))\n",
    "\n",
    "model.add(Dense(units = 6, activation = 'softmax'))\n",
    "\n",
    "# Compiling the CNN\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystop = EarlyStopping(patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', \n",
    "                                            patience=3, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [earlystop, learning_rate_reduction]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"emotion\"] = test_df[\"emotion\"].replace({0: 'Anger', 1: 'Disgust',2: 'Fear',3: 'Happiness',4: 'Sadness',5: 'Surprise'}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"emotion\"] = train_df[\"emotion\"].replace({0: 'Anger', 1: 'Disgust',2: 'Fear',3: 'Happiness',4: 'Sadness',5: 'Surprise'}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_df[\"emotion\"] = validate_df[\"emotion\"].replace({0: 'Anger', 1: 'Disgust',2: 'Fear',3: 'Happiness',4: 'Sadness',5: 'Surprise'}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_train = train_df.shape[0]\n",
    "total_validate = validate_df.shape[0]\n",
    "total_test = test_df.shape[0]\n",
    "batch_size=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11475 validated image filenames belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    train_df, \n",
    "    x_col='image',\n",
    "    y_col='emotion',\n",
    "    target_size=IMAGE_SIZE,\n",
    "    class_mode='categorical',\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1433 validated image filenames belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "validate_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    ")\n",
    "\n",
    "validate_generator = validate_datagen.flow_from_dataframe(\n",
    "    validate_df, \n",
    "    x_col='image',\n",
    "    y_col='emotion',\n",
    "    target_size=IMAGE_SIZE,\n",
    "    class_mode='categorical',\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1438 validated image filenames belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    test_df, \n",
    "    x_col='image',\n",
    "    y_col='emotion',\n",
    "    target_size=IMAGE_SIZE,\n",
    "    class_mode='categorical',\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "180/180 [==============================] - 194s 1s/step - loss: 1.7230 - accuracy: 0.2659 - val_loss: 1.5856 - val_accuracy: 0.3401\n",
      "Epoch 2/50\n",
      "180/180 [==============================] - 132s 732ms/step - loss: 1.5279 - accuracy: 0.3763 - val_loss: 1.4443 - val_accuracy: 0.3992\n",
      "Epoch 3/50\n",
      "180/180 [==============================] - 139s 774ms/step - loss: 1.3904 - accuracy: 0.4429 - val_loss: 1.2597 - val_accuracy: 0.5014\n",
      "Epoch 4/50\n",
      "180/180 [==============================] - 142s 788ms/step - loss: 1.2365 - accuracy: 0.5102 - val_loss: 1.1320 - val_accuracy: 0.5633\n",
      "Epoch 5/50\n",
      "180/180 [==============================] - 123s 681ms/step - loss: 1.1287 - accuracy: 0.5548 - val_loss: 1.0526 - val_accuracy: 0.5974\n",
      "Epoch 6/50\n",
      "180/180 [==============================] - 123s 682ms/step - loss: 1.0450 - accuracy: 0.5958 - val_loss: 0.9453 - val_accuracy: 0.6426\n",
      "Epoch 7/50\n",
      "180/180 [==============================] - 122s 677ms/step - loss: 0.9680 - accuracy: 0.6319 - val_loss: 0.9926 - val_accuracy: 0.6203\n",
      "Epoch 8/50\n",
      "180/180 [==============================] - 127s 706ms/step - loss: 0.9305 - accuracy: 0.6465 - val_loss: 0.8905 - val_accuracy: 0.6634\n",
      "Epoch 9/50\n",
      "180/180 [==============================] - 126s 698ms/step - loss: 0.8651 - accuracy: 0.6736 - val_loss: 0.7946 - val_accuracy: 0.7191\n",
      "Epoch 10/50\n",
      "180/180 [==============================] - 126s 700ms/step - loss: 0.8269 - accuracy: 0.6853 - val_loss: 0.7504 - val_accuracy: 0.7267\n",
      "Epoch 11/50\n",
      "180/180 [==============================] - 126s 697ms/step - loss: 0.7893 - accuracy: 0.7013 - val_loss: 0.7396 - val_accuracy: 0.7232\n",
      "Epoch 12/50\n",
      "180/180 [==============================] - 127s 706ms/step - loss: 0.7684 - accuracy: 0.7145 - val_loss: 0.8163 - val_accuracy: 0.6961\n",
      "Epoch 13/50\n",
      "180/180 [==============================] - 125s 693ms/step - loss: 0.7380 - accuracy: 0.7231 - val_loss: 0.7779 - val_accuracy: 0.7121\n",
      "Epoch 14/50\n",
      "180/180 [==============================] - 126s 697ms/step - loss: 0.7052 - accuracy: 0.7330 - val_loss: 0.6731 - val_accuracy: 0.7524\n",
      "Epoch 15/50\n",
      "180/180 [==============================] - 125s 693ms/step - loss: 0.6790 - accuracy: 0.7437 - val_loss: 0.6884 - val_accuracy: 0.7413\n",
      "Epoch 16/50\n",
      "180/180 [==============================] - 127s 702ms/step - loss: 0.6447 - accuracy: 0.7597 - val_loss: 0.7117 - val_accuracy: 0.7420\n",
      "Epoch 17/50\n",
      "180/180 [==============================] - 125s 692ms/step - loss: 0.6404 - accuracy: 0.7619 - val_loss: 0.6900 - val_accuracy: 0.7497\n",
      "Epoch 18/50\n",
      "180/180 [==============================] - 124s 689ms/step - loss: 0.6238 - accuracy: 0.7686 - val_loss: 0.6953 - val_accuracy: 0.7413\n",
      "Epoch 19/50\n",
      "180/180 [==============================] - 125s 696ms/step - loss: 0.6109 - accuracy: 0.7722 - val_loss: 0.7858 - val_accuracy: 0.7017\n",
      "Epoch 20/50\n",
      "180/180 [==============================] - 125s 693ms/step - loss: 0.5929 - accuracy: 0.7787 - val_loss: 0.5983 - val_accuracy: 0.7712\n",
      "Epoch 21/50\n",
      "180/180 [==============================] - 125s 691ms/step - loss: 0.5714 - accuracy: 0.7910 - val_loss: 0.6228 - val_accuracy: 0.7629\n",
      "Epoch 22/50\n",
      "180/180 [==============================] - 125s 696ms/step - loss: 0.5523 - accuracy: 0.7949 - val_loss: 0.5933 - val_accuracy: 0.7733\n",
      "Epoch 23/50\n",
      "180/180 [==============================] - 125s 694ms/step - loss: 0.5427 - accuracy: 0.8018 - val_loss: 0.6858 - val_accuracy: 0.7483\n",
      "Epoch 24/50\n",
      "180/180 [==============================] - 124s 690ms/step - loss: 0.5425 - accuracy: 0.7949 - val_loss: 0.5937 - val_accuracy: 0.7830\n",
      "Epoch 25/50\n",
      "180/180 [==============================] - 131s 728ms/step - loss: 0.5177 - accuracy: 0.8098 - val_loss: 0.5080 - val_accuracy: 0.8032\n",
      "Epoch 26/50\n",
      "180/180 [==============================] - 99s 549ms/step - loss: 0.5041 - accuracy: 0.8128 - val_loss: 0.5920 - val_accuracy: 0.7643\n",
      "Epoch 27/50\n",
      "180/180 [==============================] - 104s 578ms/step - loss: 0.5136 - accuracy: 0.8112 - val_loss: 0.5757 - val_accuracy: 0.7816\n",
      "Epoch 28/50\n",
      "180/180 [==============================] - 103s 574ms/step - loss: 0.5011 - accuracy: 0.8142 - val_loss: 0.5584 - val_accuracy: 0.7844\n",
      "Epoch 29/50\n",
      "180/180 [==============================] - 102s 568ms/step - loss: 0.4743 - accuracy: 0.8281 - val_loss: 0.5382 - val_accuracy: 0.8122\n",
      "Epoch 30/50\n",
      "180/180 [==============================] - 103s 573ms/step - loss: 0.4724 - accuracy: 0.8229 - val_loss: 0.5792 - val_accuracy: 0.7844\n",
      "Epoch 31/50\n",
      "180/180 [==============================] - 106s 586ms/step - loss: 0.4608 - accuracy: 0.8266 - val_loss: 0.5719 - val_accuracy: 0.7914\n",
      "Epoch 32/50\n",
      "180/180 [==============================] - 105s 581ms/step - loss: 0.4624 - accuracy: 0.8294 - val_loss: 0.5367 - val_accuracy: 0.8018\n",
      "Epoch 33/50\n",
      "180/180 [==============================] - 104s 580ms/step - loss: 0.4504 - accuracy: 0.8332 - val_loss: 0.5343 - val_accuracy: 0.8157\n",
      "Epoch 34/50\n",
      "180/180 [==============================] - 105s 583ms/step - loss: 0.4301 - accuracy: 0.8381 - val_loss: 0.5681 - val_accuracy: 0.7789\n",
      "Epoch 35/50\n",
      "180/180 [==============================] - 106s 589ms/step - loss: 0.4389 - accuracy: 0.8400 - val_loss: 0.5663 - val_accuracy: 0.7942\n",
      "Epoch 36/50\n",
      "180/180 [==============================] - 103s 574ms/step - loss: 0.4396 - accuracy: 0.8382 - val_loss: 0.5283 - val_accuracy: 0.8067\n",
      "Epoch 37/50\n",
      "180/180 [==============================] - 107s 595ms/step - loss: 0.4185 - accuracy: 0.8427 - val_loss: 0.6775 - val_accuracy: 0.7552\n",
      "Epoch 38/50\n",
      "180/180 [==============================] - 105s 581ms/step - loss: 0.4168 - accuracy: 0.8468 - val_loss: 0.5271 - val_accuracy: 0.8122\n",
      "Epoch 39/50\n",
      "180/180 [==============================] - 105s 584ms/step - loss: 0.4184 - accuracy: 0.8452 - val_loss: 0.5825 - val_accuracy: 0.7907\n",
      "Epoch 40/50\n",
      "180/180 [==============================] - 107s 592ms/step - loss: 0.3898 - accuracy: 0.8580 - val_loss: 0.4643 - val_accuracy: 0.8387\n",
      "Epoch 41/50\n",
      "180/180 [==============================] - 107s 597ms/step - loss: 0.3955 - accuracy: 0.8549 - val_loss: 0.5087 - val_accuracy: 0.8192\n",
      "Epoch 42/50\n",
      "180/180 [==============================] - 106s 588ms/step - loss: 0.3945 - accuracy: 0.8551 - val_loss: 0.6209 - val_accuracy: 0.7865\n",
      "Epoch 43/50\n",
      "180/180 [==============================] - 132s 733ms/step - loss: 0.3837 - accuracy: 0.8625 - val_loss: 0.5276 - val_accuracy: 0.8025\n",
      "Epoch 44/50\n",
      "180/180 [==============================] - 107s 592ms/step - loss: 0.3657 - accuracy: 0.8686 - val_loss: 0.5260 - val_accuracy: 0.8046\n",
      "Epoch 45/50\n",
      "180/180 [==============================] - 105s 584ms/step - loss: 0.3695 - accuracy: 0.8652 - val_loss: 0.5086 - val_accuracy: 0.8255\n",
      "Epoch 46/50\n",
      "180/180 [==============================] - 110s 609ms/step - loss: 0.3692 - accuracy: 0.8664 - val_loss: 0.4858 - val_accuracy: 0.8178\n",
      "Epoch 47/50\n",
      "180/180 [==============================] - 108s 598ms/step - loss: 0.3715 - accuracy: 0.8706 - val_loss: 0.5307 - val_accuracy: 0.8185\n",
      "Epoch 48/50\n",
      "180/180 [==============================] - 116s 645ms/step - loss: 0.3567 - accuracy: 0.8715 - val_loss: 0.4671 - val_accuracy: 0.8303\n",
      "Epoch 49/50\n",
      "180/180 [==============================] - 116s 647ms/step - loss: 0.3569 - accuracy: 0.8696 - val_loss: 0.5227 - val_accuracy: 0.8178\n",
      "Epoch 50/50\n",
      "180/180 [==============================] - 132s 734ms/step - loss: 0.3413 - accuracy: 0.8765 - val_loss: 0.4464 - val_accuracy: 0.8373\n"
     ]
    }
   ],
   "source": [
    "epochs = 3 if FAST_RUN else 50\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator, \n",
    "    epochs=epochs,\n",
    "    validation_data=test_generator, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"model.emotion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.emotion\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('model.emotion')  # creates a HDF5 file 'my_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 10s 450ms/step - loss: 0.4459 - accuracy: 0.8381\n",
      "Test Loss is 0.4459391236305237\n",
      "Test Accuracy is 0.838101863861084\n"
     ]
    }
   ],
   "source": [
    "ModelLoss, ModelAccuracy = model.evaluate(validate_generator)\n",
    "\n",
    "print('Test Loss is {}'.format(ModelLoss))\n",
    "print('Test Accuracy is {}'.format(ModelAccuracy ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x1b7af3d2e50>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(\"model.emotion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 1273423,
     "sourceId": 2136412,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30674,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
